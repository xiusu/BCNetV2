model:
    #channels: [32, 32, 16, 30, 30, 24, 55, 55, 24, 58, 58, 32, 98, 98, 32, 120, 120, 32, 58, 58, 64, 236, 236, 64, 238, 238, 64, 255, 255, 64, 156, 156, 96, 288, 288, 96, 243, 243, 96, 190, 190, 160, 490, 490, 160, 418, 418, 160, 341, 341, 320, 952]
    channels: [64, 64, 128, 128, 256, 256, 256, 256, 512, 512, 512, 512, 512, 512, 512, 512]
    backbone:
      # [n, stride, c_in, c_out, [expand_ratio], channel_search, [op]]
      conv_stem: [2, 1, 3, 64, [], False, ['conv3x3']]
      maxp1: [1, 2, 1, 1, [], False, ['maxpool2x2']]
      stage1: [2, 1, 64, 128, [], False, ['conv3x3']]
      maxp2: [1, 2, 1, 1, [], False, ['maxpool2x2']]
      stage2: [4, 1, 128, 256, [], False, ['conv3x3']]
      maxp3: [1, 2, 1, 1, [], False, ['maxpool2x2']]
      stage3: [4, 1, 256, 512, [], False, ['conv3x3']]
      maxp4: [1, 2, 1, 1, [], False, ['maxpool2x2']]
      stage4: [4, 1, 512, 512, [], False, ['conv3x3']]
      final_pooling: True
    head:
      linear1:
        dim_in: 512
        dim_out: 10
    loss_type: 'softmax'
    width_multiplier: 1

retrain:
    flag: True
    strategy:
        max_iter:  196000 #196000*4 : 500,  234000 * 4 : 600epoch
        max_iter_keeptrain: 41000 #41000 100个epoch  for cifar10,390.625一个epoch
        optimizer:
            type: 'SGD'
            lr: 0.1  # in proxyless: 0.0125 per gpu
            weight_decay: 0.0001
            momentum: 0.9
            nesterov: False
        resume: False
        lr_scheduler:
            #base_lr: 0.12
            lr_steps: [62500, 93750, 117190, 156250] # 160 epoch 62500, 240 epoch 93750, 300 epoch 117190, 400 epoch 156250, 500 epoch 195312
            lr_mults: [0.1, 0.1, 0.1, 0.1]
            warmup_steps: 0  # warmup epochs: 5 steps=5*391=1955
            warmup_strategy: 'gradual'
            warmup_lr: 0.1
            decay_stg: 'step' #'cosine'
            # final lr in cosine strategy
            alpha: 0.00001
            # how many iterations it takes to decay lr to 'alpha'
            decay_step: 186000
        bin_search: True
        bin_config:
            P_train: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]
            Efficient_topk: 100
            skip_list: [[]]    # mobilenetv2

        task_type: 'imagenet'
        snapshot_freq: 1000 #1000
        print_freq: 100
        basic_path: '../generalNAS_exp/cifar10_VGG19_fairnet_20list_0.5'
        save_path: '../generalNAS_exp/cifar10_VGG19_ori_2_P_train0.1_wd1/retrain' #defined by basic_path

    data:
        workers: 8  # dataloader worker num
        task_type: 'imagenet'
        data_type: 'ssst'
        scatter_mode: False
        final_height: 32
        final_width: 32
        final_channel: 3
        augmentation:
            padding:
                padding: 4
            random_crop:
                output_size: 32
            affine:
                mirror:
                    mirror_prob: 0.5
            # normalize
            normalize:
                normalize_type: 'mean_std'
                mean: [132.776, 134.11, 135.48] #[0.53129727, 0.5259391, 0.52069134] * 255?
                std: [71.3277279, 72.6896523, 73.7925273] #[0.28938246, 0.28505746, 0.27971658]*255?
        imagenet:
            type: 'classification'
            task: 'imagenet'
            json_path: '/mnt/lustre/suxiu/dataset/cifar_10/train.json'
            prefix: '/mnt/lustre/suxiu/dataset/cifar_10/train'
            batch_size: 16 # for single gpu

sample:
    flag: True
    epoch: 1  #sample epoch
    flops_constrant: 0.5  #330000000, changed to percent
    sampler:
        type: 'evolution'
        Deduce_P: 0.015
        kwargs:
            log_path: '../generalNAS_exp/imagenet_greedynas_nopool_search'
            Sample_test_num: None # del this function, can be added in the future
            train_eval: True
            #cal_time: 6
            search_num: 10 #10
            sample_num: 1
            pop_size: 40 #40 #50
            Bet_pop_size: 40 #30
            n_gens: 80 #80 #20
            extension_loc: [[]]

    strategy:
        task_type: 'imagenet-test'
        snapshot_freq: 100
        print_freq: 100
        use_basic_path: True
        save_path: '../generalNAS_exp/imagenet_mbnetv2_retrain/greedysample' #meiyong？  '../generalNAS_exp/imagenet_greedynas_nopool_search'
        load_name: None #'iter_70000_ckpt.pth.tar'  #epoch == 1 and load_name == None for save_path and load_name useful

    data:
        workers: 8  # dataloader worker num
        task_type: 'imagenet-test'
        data_type: 'ssst'
        scatter_mode: False
        final_height: 32
        final_width: 32
        final_channel: 3
        augmentation:
            normalize:
                normalize_type: 'mean_std'
                mean: [132.776, 134.11, 135.48] #[0.53129727, 0.5259391, 0.52069134] * 255?
                std: [71.3277279, 72.6896523, 73.7925273] #[0.28938246, 0.28505746, 0.27971658]*255?
        imagenet:
            type: 'classification'
            task: 'imagenet'
            json_path: '/mnt/lustre/suxiu/dataset/cifar_10/test.json'
            prefix: '/mnt/lustre/suxiu/dataset/cifar_10/test'
            batch_size: 128 # for single gpu

final_train:
    flag: True
    train_mode: 'retrain'  #it can be retrain or finetune
    # FLOPs: 333,598,784 FLOPs
    strategy:
      retrain:
        max_iter: 234400 #196000
        optimizer:
            type: 'SGD'
            lr: 0.1  # in proxyless: 0.0125 per gpu
            weight_decay: 0.0001
            momentum: 0.9
            nesterov: False
        resume: False
        lr_scheduler:
            #base_lr: 0.12
            lr_steps: [62500, 93750, 156250, 195312]  #62500=160ep, 93750 = 240ep, 117190=300ep, 156250=400ep, 195312=500ep
            lr_mults: [0.1, 0.1, 0.1, 0.1]
            warmup_steps: 0  # warmup epochs: 5 steps=5*2503=12515
            warmup_strategy: 'gradual'
            warmup_lr: 0.2
            decay_stg: 'step'  #'cosine'
            # final lr in cosine strategy
            alpha: 0.00001
            # how many iterations it takes to decay lr to 'alpha'
            decay_step: 186000
        task_type: 'imagenet'
        snapshot_freq: 400
        print_freq: 100
        use_basic_path: True
        save_path: '../generalNAS_exp/imagenet_mbnetv2_retrain/final_train'

      finetune:
        max_iter: 234400 #196000 = 500ep, 234400 = 600ep
        optimizer:
          type: 'SGD'
          lr: 0.1  # in proxyless: 0.0125 per gpu
          weight_decay: 0.0001
          momentum: 0.9
          nesterov: False
        resume: False
        lr_scheduler:
          #base_lr: 0.12
          lr_steps: [62500, 93750, 156250, 195312]  #62500=160ep, 93750 = 240ep, 117190=300ep, 156250=400ep, 195312=500ep
          lr_mults: [0.1, 0.1, 0.1, 0.1]
          warmup_steps: 0  # warmup epochs: 5 steps=5*390.625=1953
          warmup_strategy: 'gradual'
          warmup_lr: 0.2
          decay_stg: 'step'
          # final lr in cosine strategy
          alpha: 0.00001
          # how many iterations it takes to decay lr to 'alpha'
          decay_step: 186000
        task_type: 'imagenet'
        snapshot_freq: 400
        print_freq: 100
        use_basic_path: True
        save_path: '../generalNAS_exp/imagenet_mbnetv2_retrain/final_train'

    data:
        workers: 4  # dataloader worker num
        task_type: 'imagenet'
        data_type: 'ssst'
        scatter_mode: False
        final_height: 32
        final_width: 32
        final_channel: 3
        augmentation:
            padding:
                padding: 4
            random_crop:
                output_size: 32
            affine:
                mirror:
                    mirror_prob: 0.5

            # normalize
            normalize:
                normalize_type: 'mean_std'
                mean: [132.776, 134.11, 135.48] #[0.53129727, 0.5259391, 0.52069134] * 255?
                std: [71.3277279, 72.6896523, 73.7925273] #[0.28938246, 0.28505746, 0.27971658]*255?
        imagenet:
            type: 'classification'
            task: 'imagenet'
            json_path: '/mnt/lustre/suxiu/dataset/cifar_10/train.json'
            prefix: '/mnt/lustre/suxiu/dataset/cifar_10/train'
            batch_size: 16 # for single gpu



test:
    flag: True
    strategy:
        task_type: 'imagenet-test'
        snapshot_freq: 400
        print_freq: 400
        use_basic_path: True
        save_path: '../generalNAS_exp/imagenet_mbnetv2_retrain/final_train/checkpoint'
        load_iter: 138000 #140000
        start: 138000 #139000
        end: 234400 #196000
        strip: 400

    data:
        workers: 8  # dataloader worker num
        task_type: 'imagenet-test'
        data_type: 'ssst'
        scatter_mode: False
        final_height: 32
        final_width: 32
        final_channel: 3
        augmentation:
            normalize:
                normalize_type: 'mean_std'
                mean: [132.776, 134.11, 135.48] #[0.53129727, 0.5259391, 0.52069134] * 255?
                std: [71.3277279, 72.6896523, 73.7925273] #[0.28938246, 0.28505746, 0.27971658]*255?
        imagenet:
            type: 'classification'
            task: 'imagenet'
            json_path: '/mnt/lustre/suxiu/dataset/cifar_10/test.json'
            prefix: '/mnt/lustre/suxiu/dataset/cifar_10/test'
            batch_size: 8 # for single gpu

